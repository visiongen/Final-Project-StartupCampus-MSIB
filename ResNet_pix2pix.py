# -*- coding: utf-8 -*-
"""Pinka_pix2pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y2OCGXZHJb8OprEFwvATcuUPsJmBsX7l
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision import utils
from PIL import Image

class ProductDataset(Dataset):
  def __init__(self, root_dir, transform=None):
    # Inisialisasi dataset dengan mendefinisikan direktori dan transformasi
    self.root_dir = root_dir
    self.list_files = os.listdir(self.root_dir) # Mendapatkan daftar nama file gambar di direktori
    self.transform = transform
    #print(self.list_files)

  def __len__(self):
    # Memberikan panjang total dataset (jumlah gambar)
    return len(self.list_files)

  def __getitem__(self, index):
    # Mendapatkan nama file gambar pada indeks tertentu
    img_file = self.list_files[index]
    img_path = os.path.join(self.root_dir, img_file) # Mendapatkan path lengkap gambar
    img = np.array(Image.open(img_path))  # Membuaka gambar sebagai array numpy
    width = img.shape[1] // 2  # Menentukan lebar setengah citra

    # Memisahkan citra menjadi bagian input (edge) dan gambar asli (real)
    real = img[:, :width, :]
    edge = img[:, width:, :]

    # Jika transformasi telah ditentukan, lakukan transformasi pada kedua gambar
    if self.transform:
      real = self.transform(real)
      edge = self.transform(edge)

    # Mengembalikan pasangan gambar (edge, real) setelah pemrosesan
    return real, edge

# Definisi transformasi yang akan diterapkan pada setiap gambar
transform = transforms.Compose([
    transforms.ToPILImage(),        # Menkonversi array numpy menjadi objek PIL Image
    transforms.Resize((256, 256)),  # Meresize citra menjadi ukuran (256, 256)
    transforms.ToTensor(),          # Mengoversi PIL Image menjadi Tensor
])

from google.colab import drive
drive.mount('/content/drive')

# Path ke direktori dataset
TRAIN_PATH = '/content/drive/MyDrive/Final Project/data/datasets/train'
TEST_PATH = '/content/drive/MyDrive/Final Project/data/datasets/test'
VAL_PATH = '/content/drive/MyDrive/Final Project/data/datasets/val'

# Membuat instance dari kelas ProductDataset untuk dataset latihan
data = ProductDataset(root_dir=TRAIN_PATH, transform=transform)

# Membuat DataLoader untuk dataset latihan
dataloader = DataLoader(data, batch_size=36, shuffle=True)

i = 0
for real, edge in dataloader:
  print(real.shape, edge.shape)
  i+=1
  if i == 2:
    break

for real, edge in dataloader:
  real = utils.make_grid(real, normalize=True, nrow=6)
  edge = utils.make_grid(edge, normalize=True, nrow=6)

  real = real.permute(1,2,0).numpy()
  edge = edge.permute(1,2,0).numpy()

  #plt.figure(figsize=(10,10))

  plt.subplot(1,2,1)
  plt.imshow(real)
  plt.title("real image")
  plt.xticks([])
  plt.yticks([])

  plt.subplot(1,2,2)
  plt.imshow(edge)
  plt.title("input image")
  plt.xticks([])
  plt.yticks([])

  plt.show()
  break

import torch.nn as nn
import torch.nn.functional as F
import torch

def weights_init_normal(m):
  classname = m.__class__.__name__
  if classname.find("Conv") != -1:
    torch.nn.init.normal_(m.weight.data, 0.0, 0.02)
  elif classname.find("BatchNorm2d") != -1:
    torch.nn.init.normal_(m.weight.data, 1.0, 0.02)
    torch.nn.init.constant_(m.bias.data, 0.0)

import torch.nn as nn

class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()

        self.block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.InstanceNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.InstanceNorm2d(out_channels),
        )

    def forward(self, x):
        return x + self.block(x)

class GeneratorResNet(nn.Module):
    def __init__(self, in_channels, out_channels, num_residual_blocks=9):
        super(GeneratorResNet, self).__init__()

        # Initial convolutional layer
        self.initial = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=3),
            nn.InstanceNorm2d(64),
            nn.ReLU(inplace=True),
        )

        # Downsampling
        self.downsampling = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.InstanceNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
            nn.InstanceNorm2d(256),
            nn.ReLU(inplace=True),
        )

        # Residual blocks
        self.residual_blocks = nn.Sequential(
            *[ResidualBlock(256, 256) for _ in range(num_residual_blocks)]
        )

        # Upsampling
        self.upsampling = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.InstanceNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.InstanceNorm2d(64),
            nn.ReLU(inplace=True),
        )

        # Output layer
        self.output_layer = nn.Conv2d(64, out_channels, kernel_size=7, stride=1, padding=3)

    def forward(self, x):
        x = self.initial(x)
        x = self.downsampling(x)
        x = self.residual_blocks(x)
        x = self.upsampling(x)
        x = self.output_layer(x)
        return torch.tanh(x)

class Discriminator(nn.Module):
    def __init__(self, in_channels=6):  # Changed in_channels to 6
        super(Discriminator, self).__init__()

        def discriminator_block(in_filters, out_filters, normalization=True):
            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]
            if normalization:
                layers.append(nn.InstanceNorm2d(out_filters))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *discriminator_block(in_channels, 64, normalization=False),  # Changed in_channels to 6
            *discriminator_block(64, 128),
            *discriminator_block(128, 256),
            *discriminator_block(256, 512),
            nn.ZeroPad2d((1, 0, 1, 0)),
            nn.Conv2d(512, 1, 4, padding=1, bias=False)
        )

    def forward(self, real, edge):
        img_input = torch.cat((real, edge), 1)
        return self.model(img_input)

import argparse
import os
import numpy as np
import math
import itertools
import time
import time
import datetime
import sys

import torchvision.transforms as transforms
from torchvision.utils import save_image

from torch.utils.data import DataLoader
from torchvision import datasets
from torch.autograd import Variable

import torch.nn as nn
import torch.nn.functional as F
import torch

from torchsummary import summary

epoch = 0
n_epochs = 30
dataset_name = "fashion"
batch_size = 1
lr = 0.0002
b1 = 0.5
b2 = 0.999
decay_epoch = 100
n_cpu = 8
img_height = 256
img_width = 256
channels = 3
sample_interval = 200
checkpoint_interval = 1

os.makedirs('/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/images', exist_ok=True)
os.makedirs('/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models', exist_ok=True)

cuda = True if torch.cuda.is_available() else False
cuda

import torch

# Cek apakah CUDA (GPU) tersedia
if torch.cuda.is_available():
    # Dapatkan nama GPU
    gpu_name = torch.cuda.get_device_name(0)
    print(f'GPU tersedia: {gpu_name}')
else:
    print('Tidak ada GPU yang tersedia.')

criterion_GAN = torch.nn.MSELoss()
criterion_pixelwise = torch.nn.L1Loss()

lambda_pixel = 100

patch = (1, img_height // 2 ** 4, img_width // 2 ** 4)
patch

# Menentukan jumlah saluran masukan dan keluaran
in_channels = 3  # Jumlah saluran masukan
out_channels = 3  # Jumlah saluran keluaran

generator = GeneratorResNet(in_channels, out_channels)
discriminator = Discriminator()

if cuda:
  generator = generator.cuda()
  discriminator = discriminator.cuda()
  criterion_GAN.cuda()
  criterion_pixelwise.cuda()

if next(generator.parameters()).is_cuda:
    print("Model berada di GPU.")
else:
    print("Model berada di CPU.")

if next(discriminator.parameters()).is_cuda:
    print("Model berada di GPU.")
else:
    print("Model berada di CPU.")

summary(generator, input_size=(in_channels, 256, 256))

summary(discriminator, input_size=[(3, 256, 256), (3, 256, 256)])

if epoch != 0:
  generator.load_state_dict(torch.load(f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/generator_{epoch}"))
  discriminator.load_state_dict(torch.load(f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/discriminator_{epoch}"))
else:
  generator.apply(weights_init_normal)
  discriminator.apply(weights_init_normal)

optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))

transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((img_height, img_width), Image.BICUBIC),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

train_dataloader = DataLoader(
    ProductDataset(root_dir=TRAIN_PATH, transform=transform),
    batch_size=batch_size,
    shuffle=True,
    num_workers=n_cpu,
)

val_dataloader = DataLoader(
    ProductDataset(root_dir=VAL_PATH, transform=transform),
    batch_size=10,
    shuffle=True,
    num_workers=1,
)

Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
Tensor

def sample_images(batches_done):
  imgs = next(iter(val_dataloader))
  img_edge = Variable(imgs[1].type(Tensor))
  img_real = Variable(imgs[0].type(Tensor))
  img_generator = generator(img_edge)
  img_sample = torch.cat((img_edge.data, img_generator.data, img_real.data), -2)
  save_image(img_sample, f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/images/{batches_done}.jpg", nrow=5, normalize=True)

d_loss_list = []
g_loss_list = []
pixel_loss_list = []
gan_loss_list = []

from skimage.metrics import peak_signal_noise_ratio

psnr = []
for i, batch in enumerate(train_dataloader):
    img_edge = Variable(batch[1].type(Tensor)).cuda()
    img_real = Variable(batch[0].type(Tensor)).cuda()
    img_generator = generator(img_edge)

    # Use peak_signal_noise_ratio instead of PeakSignalNoiseRatio
    metric_psnr = peak_signal_noise_ratio(img_generator.cpu().detach().numpy(), img_real.cpu().detach().numpy())
    psnr.append(metric_psnr)

np.mean(np.array(psnr))

import torch
from torchvision.models import inception_v3
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import numpy as np
from scipy.stats import entropy

# Fungsi untuk menghitung Inception Score
def calculate_inception_score(generator, num_samples, batch_size=50, device='cuda'):
    # Generate samples using the generator
    generated_images = []
    for _ in tqdm(range(num_samples // batch_size)):
        noise = torch.randn(batch_size, 3, 256, 256).to(device)
        generated_image = generator(noise).cpu().detach()
        generated_images.append(generated_image)

    # Stack generated images
    generated_images = torch.cat(generated_images, dim=0)

    # Load InceptionV3 model
    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)
    inception_model.eval()

    # Calculate predictions
    preds = []
    with torch.no_grad():
        for i in tqdm(range(0, num_samples, batch_size)):
            batch = generated_images[i:i+batch_size].to(device)
            pred = F.softmax(inception_model(batch), dim=1)
            preds.append(pred)

    preds = torch.cat(preds, dim=0)

    # Calculate Inception Score
    scores = []
    for i in tqdm(range(preds.shape[0] // 50)):
        part = preds[i * 50 : (i + 1) * 50].cpu().numpy()
        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))
        kl = np.mean(np.sum(kl, 1))
        scores.append(np.exp(kl))

    inception_score = np.mean(scores)
    return inception_score

# Setelah proses training selesai
final_inception_score = calculate_inception_score(generator, num_samples=100)
print(f'Final Inception Score: {final_inception_score}')

prev_time = time.time()
filecsv = '/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/loss.csv'

for epoch in range(epoch, n_epochs):
    d_loss = []
    g_loss = []
    pixel_loss = []
    gan_loss = []

    for i, batch in enumerate(train_dataloader):
        img_edge = Variable(batch[1].type(Tensor)).cuda()
        img_real = Variable(batch[0].type(Tensor)).cuda()

        valid = torch.tensor(np.ones((img_edge.size(0), *patch)), dtype=torch.float32, device='cuda').requires_grad_(False)
        fake = torch.tensor(np.zeros((img_edge.size(0), *patch)), dtype=torch.float32, device='cuda').requires_grad_(False)

        optimizer_G.zero_grad()

        img_generator = generator(img_edge)

        pred_fake = discriminator(img_generator, img_edge)
        loss_GAN = criterion_GAN(pred_fake, valid)
        loss_pixel = criterion_pixelwise(img_generator, img_real)

        loss_G = loss_GAN + lambda_pixel * loss_pixel

        loss_G.backward()

        optimizer_G.step()

        optimizer_D.zero_grad()

        pred_real = discriminator(img_real, img_edge)
        loss_real = criterion_GAN(pred_real, valid)

        pred_fake = discriminator(img_generator.detach(), img_edge)
        loss_fake = criterion_GAN(pred_fake, fake)

        loss_D = 0.5 * (loss_real + loss_fake)

        loss_D.backward()
        optimizer_D.step()

        batches_done = epoch * len(train_dataloader) + i
        batches_left = n_epochs * len(train_dataloader) - batches_done
        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))
        prev_time = time.time()

        sys.stdout.write(
            f"\r[Epoch {epoch, n_epochs}] [Batch {i, len(train_dataloader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}, pixel: {loss_pixel.item()}, adv: {loss_GAN.item()}] ETA: {time_left}"
        )
        d_loss.append(loss_D.item())
        g_loss.append(loss_G.item())
        pixel_loss.append(loss_pixel.item())
        gan_loss.append(loss_GAN.item())

        if batches_done % sample_interval == 0:
            sample_images(batches_done)
            d_loss_list.append(np.mean(np.array(d_loss)))
            g_loss_list.append(np.mean(np.array(g_loss)))
            pixel_loss_list.append(np.mean(np.array(pixel_loss)))
            gan_loss_list.append(np.mean(np.array(gan_loss)))

    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:
        torch.save(generator.state_dict(), f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/generator_{epoch}.pth")
        torch.save(discriminator.state_dict(), f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/discriminator_{epoch}.pth")
        torch.save({
            'epoch':epoch,
            'generator_state_dict': generator.state_dict(),
            'discriminator_state_dict': discriminator.state_dict(),
            'generator_optimizer_state_dict': optimizer_G.state_dict(),
            'discriminator_optimizer_state_dict': optimizer_D.state_dict(),
        }, f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/checkpoint_epoch_{epoch + 1}.pth")
        if epoch != 0:
          checkpoint_file = f'/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/checkpoint_epoch_{epoch}.pth'
          generator_file = f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/generator_{epoch}.pth"
          discriminator_file = f"/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/saved_models/discriminator_{epoch}.pth"
          os.remove(checkpoint_file)
          os.remove(generator_file)
          os.remove(discriminator_file)

        all_losses = {'epoch':epoch+1,
                      'discriminator_loss':np.mean(d_loss),
                      'generator_loss':np.mean(g_loss),
                      'pixel_loss':np.mean(pixel_loss),
                      'gan_loss':np.mean(gan_loss)}

        with open(filecsv, 'a', newline='') as csvfile:
          fieldnames = ['epoch', 'discriminator_loss', 'generator_loss', 'pixel_loss', 'gan_loss']
          writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
          writer.writerow(all_losses)

from math import log10, sqrt
import cv2
import numpy as np
import os

def PSNR(original, compressed):
    mse = np.mean((original - compressed) ** 2)
    if(mse == 0):
        return 100
    max_pixel = 255.0
    psnr = 20 * log10(max_pixel / sqrt(mse))
    return psnr

def calculate_PSNR_for_images(original_path, compressed_path):
    original = cv2.imread(original_path)
    compressed = cv2.imread(compressed_path, 1)
    value = PSNR(original, compressed)
    return value

def main():
    # Path ke direktori hasil gambar
    images_path = "/content/drive/MyDrive/Final Project/Pinka/Arsitektur-1/images/"

    # Daftar semua file di direktori
    image_files = os.listdir(images_path)

    # Memfilter file-file tertentu (misalnya, hanya file generated yang ingin dihitung PSNR)
    generated_files = [file for file in image_files if "generated" in file]

    # Hitung PSNR untuk setiap pasangan gambar real dan gambar yang dihasilkan
    psnr_values = []
    for generated_file in generated_files:
        real_file = generated_file.replace("fake A", "real A")
        original_path = os.path.join(images_path, real_file)
        compressed_path = os.path.join(images_path, generated_file)
        psnr_value = calculate_PSNR_for_images(original_path, compressed_path)
        psnr_values.append(psnr_value)
        print(f"PSNR value for {real_file} vs {generated_file} is {psnr_value} dB")

    # Hitung rata-rata PSNR
    average_psnr = np.mean(psnr_values)
    print(f"Average PSNR value for all pairs is {average_psnr} dB")

if __name__ == "__main__":
    main()